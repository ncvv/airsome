Tasks:
    DONE: fertig
    TBA : to be assigned
    0X -: zugewiesen, noch nicht erledigt

NO - Straßen auf Bezirk Mappen -> wir haben sowohl Adressen als auch Bezirke in der Datei, also müssen wir das glaub nicht machen 
05 - AT THE END  - Daten Visualisieren - Heatmap [Helene]

FRAGEN FÜR DIE REVIEW SESSION MIT DEN PROFS - BIS SONNTAG ABEND SAMMELN
01 - Listings, reviews preprocessing - Stemming usw durchführen [NICO]
02 - Label aus den Ratings erstellen  [! Ratings überwiegend gut]
03 - mit den REviews - nur CV da nicht für neue
04 - ohne Reviews - dann können wir mit den Eigenschaften der Wohnung das Rating vorhersagen
!! vll kurz vor dem anwenden einer Methode das ein oder andere Attribut ausschließen
07 - KMEANS
08 - Number of Reviews <=3 ausschließen
09 - Verschiedene Datasets mit verschiedenen Anzahlen an Labels bereitstellen [NICO]
10 - Grid Search CV ansehen
11 - KMEANS
Die folgenden Classifier mit Kurven und so plotten:
1 File anlegen und dann da die classification für die verschiedenen Listings benutzen
12 - KNN [KERSTIN]
13 - Naive Bayes [HELENE]
TBA - Nearest Centroid []
15 - Support Vector machines [Decision Boundaries] [NADJA]
16 - Decision Trees [DENNIS]

DONE - nur EN reviews [Kerstin]
DONE host location make the values binary - 1 in london 0 - outside london [Dennis]
DONE data type of price is polynomial -> change to real by removing $ before numbers [Helene]
DONE host response rate - in buckets ? Equal width/Equal frequency/Binary? [Nico]
DONE Daten Sammeln
DONE (andere Features crawlen): Airbnb erlaubt kein crawlen ohne IP zu blocken
DONE Nur Wohnungen nutzen die noch existieren - rausfiltern - wie viele fliegenr raus? sinnvoll? [Nico]: Untersuchung von 0.5% der Daten (~250 Listings) ergab, dass 70% der Listings immer noch online sind
DONE Bewertungen Attribute, Bezirke, - Datenset kennenlernen [ALLE]
DONE Filtern welche Attribute interessant sind ->  - mappen von Values 
DONE datenset jeder ansehen die ersten 1000  Einträge Spalte für Spalte
DONE Kommata rausmachen Nico: Nur die \n müssen rausgeparst werden bei Text. normale preprocessing Schritte, die in jeder Aufgabe anfallen
DONE how to handle NaN values in rows? [Nico] -> entscheiden, ob row deshalb gedroppt werden soll. Depends, wie viele examples gehen dadurch verloren? Mal mit dataset bei dem es zu jeder listing ID ein review gibt probieren und mal mit allen listings, egal ob reviews vorhanden sind
DONE host_neighbourhood & host_total_listings_count & street & city & requires_license RAUS
DONE host_listings_counts raus weil der calculated house_listings genauer aussieht
DONE host verification einzelne values in spalten umwandeln
DONE zip code all upper case - double entries map to first key [Nadja]
DONE was machen wir mit square feet? Column nicht ausgefüllt [Nico] -> hab die square feets mal rausgenommen, ist aber einfach umzukehren in der process() methode
DONE wie errechnet sich review-score [Helene] -> Bewertungen setzen sich nicht zusammen aus 5 unter review scores zu einem übergeordneten, der overall score wird separat angegeben
DONE Einträge raus bei denen host_id oder host_name null [Nico] -> method calls of io.remove_empty_line_df in Preprocessor.process()
TBA  reviews_xx wie damit umgehen? -> Einmal classification mit und ohne reviews, da halt jeweils drin/raus
TBA  evtl. raus neighbourhood -> Mal mit/ohne probieren



Presentation:
    - reviews_xx veranschaulichen >> & implicationen erläutern (see RapidMiner statistics)


Report wir gehen davon aus dass die Listings ehrlich sind und die gegebenen Informationen richtig sind

